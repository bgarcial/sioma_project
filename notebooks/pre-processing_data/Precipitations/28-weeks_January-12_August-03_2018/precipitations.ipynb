{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing data - 28 weeks of life of the banana plant\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_df = pd.read_csv('../../../../data/raw/FincaPorvenir/Metereologico/28-weeks_January-12_August-03_2018/' \\\n",
    "                                 'Precipitaciones_January-12_August-03_2018.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9750, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha:</th>\n",
       "      <th>Precipitación (ml)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-12 00:17:28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-12 00:47:28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-12 01:17:27</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-12 01:47:27</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-12 02:17:27</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fecha:  Precipitación (ml)\n",
       "0  2018-01-12 00:17:28                0.00\n",
       "1  2018-01-12 00:47:28                0.00\n",
       "2  2018-01-12 01:17:27                0.00\n",
       "3  2018-01-12 01:47:27                0.00\n",
       "4  2018-01-12 02:17:27                3.19"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(precipitations_df.shape)\n",
    "precipitations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. We evaluate if this dataset has null type `NaN`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:                False\n",
      "Precipitación (ml)    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(precipitations_df.isnull().any())\n",
    "precipitations_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't have null values\n",
    "\n",
    "## 1.2. Selecting  relevant index columns features\n",
    "---\n",
    "\n",
    "Since the dataset has a column called **`Fecha:`**, which is not a numerical value,\n",
    "\n",
    "it will be removed so that it does not interfere **with our subsequent scaling**, \n",
    "\n",
    "so we are only going to reference the values or samples of the column\n",
    "\n",
    "** `Precipitación (ml)` ** and assigning them to the matrix \n",
    "\n",
    "`precipitations_array` created such as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_array = precipitations_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rehape the luminosity_luxes array \n",
    "precipitations_array = precipitations_array.reshape(-1, 1)\n",
    "precipitations_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Generating descriptive data to dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Precipitación (ml)']\n",
    "precipitations_df = pd.DataFrame(precipitations_array, columns=col)\n",
    "precipitations_df_describe = precipitations_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitación (ml)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.123362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.224794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitación (ml)\n",
       "count         9750.000000\n",
       "mean             0.123362\n",
       "std              1.224794\n",
       "min              0.000000\n",
       "25%              0.000000\n",
       "50%              0.000000\n",
       "75%              0.000000\n",
       "max             44.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitations_df_describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export this descriptive data to comma separated values and java script object notation\n",
    "precipitations_df_describe.to_csv('../../../../data/interim/Precipitations/28-weeks_January-12_August-03_2018/' +'\\n' \n",
    "                              'Precipitations_Describe_January-12_August-03.cvs', sep=',', header=True, index=True)\n",
    "precipitations_df_describe.to_json('../../../../data/interim/Precipitations/28-weeks_January-12_August-03_2018/' +'\\n'\n",
    "                                     'Precipitations_Describe_January-12_August-03.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Precipitations Training and Testing datasets\n",
    "\n",
    "We have a **`precipitations_df`** dataset with 9750 samples rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9750, 1)\n"
     ]
    }
   ],
   "source": [
    "print(precipitations_array.shape)\n",
    "# precipitations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll divide it into two differents datasets:\n",
    "\n",
    "- Training dataset\n",
    "- Testing dataset\n",
    "\n",
    "This is executed through [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  \"sklearn.model_selection.train_test_split\") function of this way:\n",
    "\n",
    "`train_test_split` receive as a data parameter a numpy array, we have to turn the \n",
    "\n",
    "**`precipitations_df`** dataframe to numpy array such as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9750, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy_precipítations = precipitations_df.reset_index().values\n",
    "# numpy_precipítations = precipitations_df.values\n",
    "precipitations_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My numpy_precipítations variable now is a numpy array\n",
    "# print(numpy_precipítations.shape)\n",
    "# print(type(numpy_precipítations))\n",
    "# numpy_precipítations\n",
    "precipitations_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compose the following datasets from **`precipitations_array`** array :\n",
    "\n",
    "- `precipitations_train`, which is the training matrix\n",
    "- `precipitations_test`, the testing matrix\n",
    "\n",
    "We use the [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  \"sklearn.model_selection.train_test_split\") function to create the training and testing dataset. Their parameters are:\n",
    "\n",
    "![alt text](https://cldup.com/hukPWvvLxt-3000x3000.png \"klearn.model_selection.train_test_split\")\n",
    "\n",
    "\n",
    "- The first parameter **should be an array**, then we pass the **`precipitations_array`** which contain all column features of luminosity.\n",
    "\n",
    "Of this way, we pass all data (9750 samples rows) to from them `precipitations_train`\n",
    "\n",
    "and `precipitations_test` will be created\n",
    "\n",
    "- The `test_size=0.5` parameter means a 50% division; which means \n",
    "that half of the data goes to the test dataset and the other half \n",
    "goes to the training dataset.\n",
    "\n",
    "A good choice for the size of tests **is usually 0.2 ie 20% or 0.25 or even 30%.** \n",
    "\n",
    "In some rare cases we will have 40% but almost never 0.5 or 50%\n",
    "\n",
    "We choose 20% which means that we will have 20% of 9752 samples or observations for the test data set, \n",
    "\n",
    "in this case **9750 * 0.2 = 1950 samples or records for the test data set**\n",
    "\n",
    "\n",
    "- The `train_size` parameter is the training dataset size.  **`test_size + train_size = 1 or 100%`**, \n",
    "then isn't necessary include it, because wheter we include to `test_size = 0.2`, then the remaining \n",
    "data will be to `train_size` this means **0.8 or 80%**\n",
    "\n",
    "This means that **9750 * 0.8 = 78006  training dataset samples rows. **\n",
    "\n",
    "\n",
    "- random_state is a seed or data source for generating random values for the data sets. \n",
    "\n",
    "If this parameter is not passed, the data will be generated in a random way, but in the way as by default numpy works them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1  Creating Training and testing precipitations datasets\n",
    "---\n",
    "\n",
    "- `precipitations_train`, which is the training matrix\n",
    "- `precipitations_test`, the testing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_train, precipitations_test = train_test_split(precipitations_array, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "The dimensionality of wind_direction training dataset is: \n",
      " (7800, 1)\n",
      "\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "The dimensionality of wind_direction testing dataset is: \n",
      " (1950, 1)\n"
     ]
    }
   ],
   "source": [
    "# We have 7800 rows to luminosity_luxes_train\n",
    "print(type(precipitations_train))\n",
    "print(\"The dimensionality of wind_direction training dataset is: \" +'\\n' , precipitations_train.shape)\n",
    "print('\\n')\n",
    "\n",
    "# And we have 1950 rows to luminosity_luxes_test\n",
    "print(type(precipitations_test))\n",
    "print(\"The dimensionality of wind_direction testing dataset is: \" +'\\n' , precipitations_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the model, as you progressively learn the correlations in the training set, the better the prediction of the results in the test set.\n",
    "\n",
    "But if the model learns too much from memory the correlations of the training sets, \n",
    "\n",
    "that is to say, when one learns from memory and does not understand things, then it \n",
    "\n",
    "will have problems to predict what is happening on the set of tests, because it is \n",
    "\n",
    "learned for difficult correlations, if the logic is not well understood and you can \n",
    "\n",
    "not make good predictions. This is called overfitting or overfitting\n",
    "\n",
    "\n",
    "The really important thing is to understand that we need to have two different datasets\n",
    "\n",
    "- Training set with which the ML model learns\n",
    "- Test set, on which we test whether the ML model correctly learned the correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  3. Feature Scaling Precipitations training and testing dataset  \n",
    "---\n",
    "\n",
    "[This article post](http://benalexkeen.com/feature-scaling-with-scikit-learn/  \"Feature Scaling with scikit-learn\") it's a great reference to explore the features scaling methods\n",
    "on scikit learn\n",
    "\n",
    "- `StandardScaler` assume that data is normally distributed at the level of each characteristic or variable. If the data is not normally distributed, it is not the best alternative to use for scaling.  \n",
    "\n",
    "- `Min-Max Scaler` it is probably the most famous scaling algorithm and what it does is resize the range to leave it in a dimension of 0 to 1 or -1 and 1 (in case there are negative values in the original dataset of input data)\n",
    "\n",
    "This scale of maximums and minimums works best for cases where standard scaling may not work properly. If the distribution is not Gaussian or the standard deviation is very small the escalation of maximums and minimums is the best idea.\n",
    "However, it is sensitive to outliers or outliers, so if there are outliers in the data it is better to consider robust scaling.\n",
    "\n",
    "- `Robust Scaler` it is similar to the previous one of maximums and minimums, only that it uses interquartile ranges instead of maximums and minimums, which makes it robust for the outliers\n",
    "\n",
    "- `Normalizer` which scales each value, dividing each value by its magnitude in n dimensional spaces for n number of characteristics.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the scaling of maximums and minimums to scale the water table data, because the standard deviation is very small, \n",
    "\n",
    "it does not have atypical values and it does not follow a normal distribution (you have to check this)\n",
    "\n",
    "We apply the maximum and minimum scaling. We provide a rank or base scale that **will be between 0 and 1** using an object,\n",
    "\n",
    "[MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html \"sklearn.preprocessing.MinMaxScaler\") which transforms each characteristic, (in this \n",
    "\n",
    "case it will be the columns feature of `Precipitación (ml)`) individually according to a given range.\n",
    "\n",
    "Product of its applicability, generates these attributes in the dataset, already transformed: \n",
    "\n",
    "![alt text](https://cldup.com/lTIv4HXgTk-3000x3000.png \"sklearn.preprocessing.MinMaxScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 We apply maximium and minimum feature scaling to Precipitations training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember our precipitations training data \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# We provide a base scale range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "print(\"Remember our precipitations training data \" + '\\n', precipitations_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [fit](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit  \"MinMaxScaler.fit\")\n",
    "we compute the maximum and minimum value of  `precipitations_train` dataset to be used in the subsequent scaling \n",
    "\n",
    "We assing these values to `minmax_scale_training` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scale_training = scaler.fit(precipitations_train.astype(float))\n",
    "# print(minmax_scale_training.data_max_)\n",
    "# http://terrapinssky.blogspot.com/2017/10/pythonresolved-dataconversionwarning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply the [transform](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.transform \"MinMaxScaler.transform\") method to transform these data to maximum and mínimum scale value. \n",
    "\n",
    "Here, with this process, the `precipitations_train` data are scaled between **0 to 1**  selected range \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform precipitations_train data to maximum and mínimum scale value. \n",
    "precipitations_minmax_training = minmax_scale_training.transform(precipitations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, these are our scaled data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"And, these are our scaled data: \" + '\\n')\n",
    "precipitations_minmax_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitations Training dataset. Minimum value after MaxMinScaler:\n",
      "Luminosity=0.0\n",
      "Precipitations Training dataset. Maximum value after MaxMinScaler:\n",
      "Luminosity=1.0\n"
     ]
    }
   ],
   "source": [
    "print('Precipitations Training dataset. Minimum value after MaxMinScaler:\\nLuminosity={:.1f}'\n",
    "      .format(precipitations_minmax_training[:,0].min()))\n",
    "\n",
    "print('Precipitations Training dataset. Maximum value after MaxMinScaler:\\nLuminosity={:.1f}'\n",
    "      .format(precipitations_minmax_training[:,0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, our  MinMaxScaler normalized training dataset is `precipitations_minmax_training` numpy array\n",
    "\n",
    "- We export this array to comma separated values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_train_df = pd.DataFrame(precipitations_minmax_training, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitación (ml)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.054924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7770</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7777</th>\n",
       "      <td>0.041193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7779</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Precipitación (ml)\n",
       "0               0.000000\n",
       "1               0.000000\n",
       "2               0.000000\n",
       "3               0.000000\n",
       "4               0.000000\n",
       "5               0.000000\n",
       "6               0.000000\n",
       "7               0.000000\n",
       "8               0.000000\n",
       "9               0.000000\n",
       "10              0.000000\n",
       "11              0.000000\n",
       "12              0.000000\n",
       "13              0.000000\n",
       "14              0.000000\n",
       "15              0.000000\n",
       "16              0.000000\n",
       "17              0.000000\n",
       "18              0.000000\n",
       "19              0.000000\n",
       "20              0.000000\n",
       "21              0.054924\n",
       "22              0.000000\n",
       "23              0.000000\n",
       "24              0.000000\n",
       "25              0.000000\n",
       "26              0.000000\n",
       "27              0.000000\n",
       "28              0.000000\n",
       "29              0.000000\n",
       "...                  ...\n",
       "7770            0.000000\n",
       "7771            0.000000\n",
       "7772            0.000000\n",
       "7773            0.000000\n",
       "7774            0.000000\n",
       "7775            0.000000\n",
       "7776            0.000000\n",
       "7777            0.041193\n",
       "7778            0.000000\n",
       "7779            0.000000\n",
       "7780            0.000000\n",
       "7781            0.000000\n",
       "7782            0.000000\n",
       "7783            0.000000\n",
       "7784            0.000000\n",
       "7785            0.000000\n",
       "7786            0.000000\n",
       "7787            0.000000\n",
       "7788            0.000000\n",
       "7789            0.000000\n",
       "7790            0.000000\n",
       "7791            0.000000\n",
       "7792            0.000000\n",
       "7793            0.000000\n",
       "7794            0.000000\n",
       "7795            0.000000\n",
       "7796            0.000000\n",
       "7797            0.000000\n",
       "7798            0.000000\n",
       "7799            0.000000\n",
       "\n",
       "[7800 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitations_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we have the dataset `precipitations_train_df` standardized and training, and export it to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_train_df.to_csv('../../../../data/processed/Precipitations/28-weeks_January-12_August-03_2018/' +'\\n' \n",
    "                                 'Precipitations_Normalized_TRAINING_January-12_August-03.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 We apply maximium and minimum feature scaling to Precipitations testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember our luminosity testing data \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# We provide a base scale range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "print(\"Remember our precipitations testing data \" + '\\n', precipitations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scale_test = scaler.fit(precipitations_test.astype(float))\n",
    "# transform luminosity_luxes_test data to maximum and mínimum scale value. \n",
    "precipitations_minmax_test = minmax_scale_test.transform(precipitations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, these are our testing scaled data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"And, these are our testing scaled data: \" + '\\n')\n",
    "precipitations_minmax_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luminosity Testing dataset. Minimum value after MaxMinScaler:\n",
      "Luminosity=0.0\n",
      "Luminosity Testing dataset. Maximum value after MaxMinScaler:\n",
      "Luminosity=1.0\n"
     ]
    }
   ],
   "source": [
    "print('Luminosity Testing dataset. Minimum value after MaxMinScaler:\\nLuminosity={:.1f}'\n",
    "      .format(precipitations_minmax_test[:,0].min()))\n",
    "\n",
    "print('Luminosity Testing dataset. Maximum value after MaxMinScaler:\\nLuminosity={:.1f}'\n",
    "      .format(precipitations_minmax_test[:,0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, our  MinMaxScaler normalized training dataset is `precipitations_minmax_test` numpy array\n",
    "\n",
    "- We export this array to comma separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_test_df = pd.DataFrame(precipitations_minmax_test, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitación (ml)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precipitación (ml)\n",
       "0                 0.0\n",
       "1                 0.0\n",
       "2                 0.0\n",
       "3                 0.0\n",
       "4                 0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(precipitations_test_df.shape)\n",
    "precipitations_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitations_test_df.to_csv('../../../../data/processed/Luminosity/28-weeks_January-12_August-03_2018/' +'\\n' \n",
    "                                 'Luminosity_Normalized_TESTING_January-12_August-03.csv', sep=',', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
